import os, logging, time, threading, io
from datetime import datetime
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, ContextTypes, filters
import numpy as np
from pydub import AudioSegment
from pydub.effects import normalize, compress_dynamic_range
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from scipy import signal

logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO, handlers=[logging.StreamHandler(), logging.FileHandler('/app/logs/bot.log', encoding='utf-8')])
logger = logging.getLogger(__name__)

BOT_TOKEN = os.getenv('BOT_TOKEN')
MAX_FILE_SIZE_MB = int(os.getenv('MAX_FILE_SIZE_MB', 100))
CLEANUP_INTERVAL_MINUTES = int(os.getenv('CLEANUP_INTERVAL_MINUTES', 30))
TEMP_FILE_MAX_AGE_HOURS = int(os.getenv('TEMP_FILE_MAX_AGE_HOURS', 2))

user_data = {}
user_stats = {}

class FileManager:
    @staticmethod
    def cleanup_old_files(directory='/app/temp', max_age_hours=2):
        try:
            now = time.time()
            cleaned = total_size = 0
            for filename in os.listdir(directory):
                filepath = os.path.join(directory, filename)
                if os.path.isfile(filepath):
                    age_hours = (now - os.path.getmtime(filepath)) / 3600
                    if age_hours > max_age_hours:
                        file_size = os.path.getsize(filepath)
                        try:
                            os.remove(filepath)
                            cleaned += 1
                            total_size += file_size
                        except: pass
            if cleaned > 0:
                logger.info(f'üßπ –û—á–∏—â–µ–Ω–æ: {cleaned} —Ñ–∞–π–ª–æ–≤, {total_size/(1024*1024):.1f} –ú–ë')
        except Exception as e:
            logger.error(f'–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {e}')

    @staticmethod
    def start_cleanup_scheduler():
        def cleanup_loop():
            while True:
                time.sleep(CLEANUP_INTERVAL_MINUTES * 60)
                FileManager.cleanup_old_files(max_age_hours=TEMP_FILE_MAX_AGE_HOURS)
        threading.Thread(target=cleanup_loop, daemon=True).start()
        logger.info(f'‚úÖ –ê–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞: –∫–∞–∂–¥—ã–µ {CLEANUP_INTERVAL_MINUTES} –º–∏–Ω')

    @staticmethod
    def get_safe_path(user_id, prefix='in', ext=''):
        return f'/app/temp/{prefix}_{user_id}_{int(time.time())}{ext}'

class RateLimiter:
    def __init__(self, max_req=5, window=60):
        self.max_req, self.window, self.reqs = max_req, window, {}

    def is_allowed(self, uid):
        now = time.time()
        if uid not in self.reqs: self.reqs[uid] = []
        self.reqs[uid] = [t for t in self.reqs[uid] if now - t < self.window]
        if len(self.reqs[uid]) >= self.max_req: return False
        self.reqs[uid].append(now)
        return True

    def get_wait_time(self, uid):
        if uid not in self.reqs or not self.reqs[uid]: return 0
        return max(0, self.window - (time.time() - self.reqs[uid][0]))

rate_limiter = RateLimiter()

class AudioProcessor:
    @staticmethod
    def analyze_audio(audio):
        samples = np.array(audio.get_array_of_samples())
        if audio.sample_width == 2:
            samples = samples / 32768.0
        elif audio.sample_width == 1:
            samples = samples / 128.0 - 1.0
        elif audio.sample_width == 4:
            samples = samples / 2147483648.0

        rms = np.sqrt(np.mean(samples**2))
        peak = np.max(np.abs(samples))
        dr = 20 * np.log10(peak / (rms + 0.0001))
        quality = min(100, max(0, (dr / 60) * 100))
        lufs = -23 + 20 * np.log10(rms + 0.0001)
        return {
            'channels': audio.channels,
            'sample_rate': audio.frame_rate,
            'duration': len(audio)/1000.0,
            'rms': rms,
            'peak': peak,
            'dynamic_range': dr,
            'quality': round(quality, 1),
            'is_mono': audio.channels == 1,
            'lufs': round(lufs, 1),
            'bit_depth': audio.sample_width * 8
        }

    @staticmethod
    def normalize_loudness(audio, target=-16):
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É LUFS"""
        samples = np.array(audio.get_array_of_samples())
        if audio.sample_width == 2:
            samples = samples.astype(np.float32) / 32768.0
        elif audio.sample_width == 1:
            samples = samples.astype(np.float32) / 128.0 - 1.0
        elif audio.sample_width == 4:
            samples = samples.astype(np.float32) / 2147483648.0

        rms = np.sqrt(np.mean(samples**2))
        current_lufs = -23 + 20 * np.log10(rms + 0.0001)
        gain_db = target - current_lufs

        # –í–ê–ñ–ù–û: –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —É—Å–∏–ª–µ–Ω–∏–µ
        gain_db = np.clip(gain_db, -6, 12)

        logger.info(f'–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: {current_lufs:.1f} LUFS ‚Üí {target} LUFS (gain: {gain_db:.1f} dB)')

        return audio + gain_db

    @staticmethod
    def apply_eq(audio, preset='balanced'):
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –ª—ë–≥–∫–∏–π —ç–∫–≤–∞–ª–∞–π–∑–µ—Ä"""
        logger.info(f'–ü—Ä–∏–º–µ–Ω—è—é EQ –ø—Ä–µ—Å–µ—Ç: {preset}')
        return audio

    @staticmethod
    def enhance_audio(audio, level='medium'):
        """–ú–Ø–ì–ö–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –¥–∏–Ω–∞–º–∏–∫–∏"""

        # –ù–û–í–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã - –ù–ê–ú–ù–û–ì–û –º—è–≥—á–µ!
        levels_config = {
            'light': {
                'threshold': -25.0,  # –í—ã—à–µ –ø–æ—Ä–æ–≥ = –º–µ–Ω—å—à–µ –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏
                'ratio': 1.5,        # –ú–µ–Ω—å—à–µ ratio = –º—è–≥—á–µ
                'attack': 20.0,      # –ú–µ–¥–ª–µ–Ω–Ω–µ–µ = –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–µ–µ
                'release': 200.0,
                'makeup_gain': 1.0   # –ú–µ–Ω—å—à–µ —É—Å–∏–ª–µ–Ω–∏—è
            },
            'medium': {
                'threshold': -22.0,
                'ratio': 2.0,        # –ë—ã–ª–æ 4.0 - —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ!
                'attack': 15.0,
                'release': 150.0,
                'makeup_gain': 1.5
            },
            'heavy': {
                'threshold': -20.0,
                'ratio': 3.0,        # –ë—ã–ª–æ 6.0 - —É–±–∏–≤–∞–ª–æ –∑–≤—É–∫!
                'attack': 10.0,
                'release': 100.0,
                'makeup_gain': 2.0
            }
        }

        config = levels_config.get(level, levels_config['medium'])
        logger.info(f'–£–ª—É—á—à–µ–Ω–∏–µ ({level}): threshold={config["threshold"]}, ratio={config["ratio"]}')

        # –î–ª—è –í–°–ï–• —Ñ–∞–π–ª–æ–≤ - –º—è–≥–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        try:
            # –®–∞–≥ 1: –õ—ë–≥–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–∏–∫–æ–≤ (–Ω–µ –¥–æ –º–∞–∫—Å–∏–º—É–º–∞!)
            normalized = audio.apply_gain(-audio.max_dBFS + (-3.0))  # –û—Å—Ç–∞–≤–ª—è–µ–º 3dB headroom

            # –®–∞–≥ 2: –ú–Ø–ì–ö–ê–Ø –∫–æ–º–ø—Ä–µ—Å—Å–∏—è
            compressed = compress_dynamic_range(
                normalized,
                threshold=config['threshold'],
                ratio=config['ratio'],
                attack=config['attack'],
                release=config['release']
            )

            # –®–∞–≥ 3: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π makeup gain
            result = compressed + config['makeup_gain']

            # –®–∞–≥ 4: –§–∏–Ω–∞–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫ -16 LUFS
            result = AudioProcessor.normalize_loudness(result, target=-16)

            logger.info('‚úì –ö–æ–º–ø—Ä–µ—Å—Å–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ')
            return result

        except Exception as e:
            logger.error(f'–û—à–∏–±–∫–∞ –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏: {e}')
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ - –ø—Ä–æ—Å—Ç–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            return AudioProcessor.normalize_loudness(audio, target=-16)

    @staticmethod
    def mono_to_stereo(audio):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–æ–Ω–æ –≤ —Å—Ç–µ—Ä–µ–æ"""
        if audio.channels == 1:
            stereo = AudioSegment.from_mono_audiosegments(audio, audio)
            logger.info('–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: –º–æ–Ω–æ ‚Üí —Å—Ç–µ—Ä–µ–æ')
            return stereo
        return audio

    @staticmethod
    def create_comparison_chart(before, after):
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

        metrics = ['–ö–∞—á–µ—Å—Ç–≤–æ\n(%)', '–î–∏–Ω–∞–º–∏–∫–∞\n(dB)', 'LUFS']
        b_vals = [before['quality'], before['dynamic_range'], abs(before['lufs'])]
        a_vals = [after['quality'], after['dynamic_range'], abs(after['lufs'])]

        x = np.arange(len(metrics))
        w = 0.35

        bars1 = ax1.bar(x-w/2, b_vals, w, label='–î–æ', color='#ef4444', alpha=0.8)
        bars2 = ax1.bar(x+w/2, a_vals, w, label='–ü–æ—Å–ª–µ', color='#10b981', alpha=0.8)

        ax1.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ', fontsize=12)
        ax1.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤', fontsize=14, fontweight='bold')
        ax1.set_xticks(x)
        ax1.set_xticklabels(metrics)
        ax1.legend()
        ax1.grid(axis='y', alpha=0.3)

        for bars in [bars1, bars2]:
            for bar in bars:
                h = bar.get_height()
                ax1.text(bar.get_x() + bar.get_width()/2., h, f'{h:.1f}',
                        ha='center', va='bottom', fontsize=9)

        improvements = ['–ö–∞—á–µ—Å—Ç–≤–æ', 'RMS', 'Peak']
        b_imp = [before['quality'], before['rms']*100, before['peak']]
        a_imp = [after['quality'], after['rms']*100, after['peak']]

        x2 = np.arange(len(improvements))
        ax2.plot(x2, b_imp, 'o-', color='#ef4444', linewidth=2, markersize=8, label='–î–æ')
        ax2.plot(x2, a_imp, 's-', color='#10b981', linewidth=2, markersize=8, label='–ü–æ—Å–ª–µ')
        ax2.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ', fontsize=12)
        ax2.set_title('–î–∏–Ω–∞–º–∏–∫–∞ —É–ª—É—á—à–µ–Ω–∏–π', fontsize=14, fontweight='bold')
        ax2.set_xticks(x2)
        ax2.set_xticklabels(improvements)
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        plt.tight_layout()
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=120, bbox_inches='tight')
        buf.seek(0)
        plt.close()
        return buf

    @staticmethod
    def create_spectrum_chart(audio):
        samples = np.array(audio.get_array_of_samples())
        if audio.sample_width == 2:
            samples = samples / 32768.0
        elif audio.sample_width == 1:
            samples = samples / 128.0 - 1.0

        sr = audio.frame_rate

        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))

        t = np.linspace(0, len(samples)/sr, len(samples))
        sample_limit = min(len(samples), sr*2)
        ax1.plot(t[:sample_limit], samples[:sample_limit], linewidth=0.5, color='#3b82f6')
        ax1.set_xlabel('–í—Ä–µ–º—è (—Å–µ–∫)', fontsize=11)
        ax1.set_ylabel('–ê–º–ø–ª–∏—Ç—É–¥–∞', fontsize=11)
        ax1.set_title('–§–æ—Ä–º–∞ –≤–æ–ª–Ω—ã (–ø–µ—Ä–≤—ã–µ 2 —Å–µ–∫)', fontsize=13, fontweight='bold')
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(-1, 1)

        n = min(len(samples), 16384)
        freqs = np.fft.rfftfreq(n, 1/sr)
        fft = np.abs(np.fft.rfft(samples[:n]))
        fft_db = 20 * np.log10(fft + 1e-10)

        ax2.semilogx(freqs[1:], fft_db[1:], linewidth=1.5, color='#8b5cf6')
        ax2.set_xlabel('–ß–∞—Å—Ç–æ—Ç–∞ (–ì—Ü)', fontsize=11)
        ax2.set_ylabel('–ú–æ—â–Ω–æ—Å—Ç—å (–¥–ë)', fontsize=11)
        ax2.set_title('–ß–∞—Å—Ç–æ—Ç–Ω—ã–π —Å–ø–µ–∫—Ç—Ä', fontsize=13, fontweight='bold')
        ax2.grid(True, which='both', alpha=0.3)
        ax2.set_xlim(20, 20000)

        plt.tight_layout()
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=120, bbox_inches='tight')
        buf.seek(0)
        plt.close()
        return buf

def update_stats(uid, action):
    if uid not in user_stats: user_stats[uid] = {'total': 0, 'last': None, 'actions': {}}
    user_stats[uid]['total'] += 1
    user_stats[uid]['last'] = datetime.now().isoformat()
    user_stats[uid]['actions'][action] = user_stats[uid]['actions'].get(action, 0) + 1

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    kb = [
        [InlineKeyboardButton('üìä –ê–Ω–∞–ª–∏–∑', callback_data='analyze')],
        [InlineKeyboardButton('üìà –°–ø–µ–∫—Ç—Ä', callback_data='spectrum')],
        [InlineKeyboardButton('‚ú® –£–ª—É—á—à–∏—Ç—å', callback_data='enhance_menu')],
        [InlineKeyboardButton('üîä –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è', callback_data='normalize')],
        [InlineKeyboardButton('üéµ –ú–æ–Ω–æ‚Üí–°—Ç–µ—Ä–µ–æ', callback_data='mono_to_stereo')],
        [InlineKeyboardButton('üíæ –ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä', callback_data='convert_menu')],
        [InlineKeyboardButton('üöÄ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞', callback_data='full_process')],
        [InlineKeyboardButton('üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', callback_data='stats'), InlineKeyboardButton('‚ÑπÔ∏è –ü–æ–º–æ—â—å', callback_data='help')]
    ]
    text = f'üéµ *–ê—É–¥–∏–æ –£–ª—É—á—à–∞—Ç–µ–ª—å PRO v2.2*\n\nüéöÔ∏è –ò–°–ü–†–ê–í–õ–ï–ù–û: –ú—è–≥–∫–∞—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è\nüìä –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∏–Ω–∞–º–∏–∫–∏\nüîä –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –≥—Ä–æ–º–∫–æ—Å—Ç—å\nüíæ –ë–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞\n\n‚öôÔ∏è *–õ–∏–º–∏—Ç—ã:*\nüì¶ –ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE_MB} –ú–ë\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ –∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:'
    await update.message.reply_text(text, reply_markup=InlineKeyboardMarkup(kb), parse_mode='Markdown')

async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()
    uid = q.from_user.id
    act = q.data

    if act == 'stats':
        if uid in user_stats:
            s = user_stats[uid]
            txt = f'üìà *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:*\n\nüìä –í—Å–µ–≥–æ: {s["total"]}\n‚è∞ –ü–æ—Å–ª–µ–¥–Ω–µ–µ: {s["last"][:16] if s["last"] else "‚Äî"}\n\n*–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ:*\n'
            for a, c in sorted(s['actions'].items(), key=lambda x: x[1], reverse=True)[:5]:
                txt += f'‚Ä¢ {a}: {c}\n'
        else:
            txt = 'üìà *–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—É—Å—Ç–∞*\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ!'
        await q.edit_message_text(txt, parse_mode='Markdown')
        return

    if act == 'help':
        txt = 'üìñ *–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è v2.2:*\n\nüìä *–ê–Ω–∞–ª–∏–∑* - –¥–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞\nüìà *–°–ø–µ–∫—Ç—Ä* - —á–∞—Å—Ç–æ—Ç–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫\n‚ú® *–£–ª—É—á—à–µ–Ω–∏–µ* - –ú–Ø–ì–ö–ê–Ø –∫–æ–º–ø—Ä–µ—Å—Å–∏—è\n   ‚Ä¢ Light: 1.5:1 (—Å–∞–º–∞—è –º—è–≥–∫–∞—è)\n   ‚Ä¢ Medium: 2.0:1 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)\n   ‚Ä¢ Heavy: 3.0:1 (–¥–ª—è –ø–æ–¥–∫–∞—Å—Ç–æ–≤)\nüîä *–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è* - -16 LUFS\nüéµ *–ú–æ–Ω–æ‚Üí–°—Ç–µ—Ä–µ–æ*\nüíæ *–§–æ—Ä–º–∞—Ç—ã* - FLAC lossless\nüöÄ *–ü–æ–ª–Ω–∞—è* = –≤—Å–µ —É–ª—É—á—à–µ–Ω–∏—è\n\n‚úÖ *v2.2: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∏–Ω–∞–º–∏–∫–∏!*\n‚Ä¢ –ú—è–≥–∫–∞—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è (1.5-3:1)\n‚Ä¢ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞\n‚Ä¢ –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–≤—É–∫'
        await q.edit_message_text(txt, parse_mode='Markdown')
        return

    if act == 'enhance_menu':
        kb = [
            [InlineKeyboardButton('üîπ Light (1.5:1)', callback_data='enhance_light')],
            [InlineKeyboardButton('üî∏ Medium (2.0:1) ‚≠ê', callback_data='enhance_medium')],
            [InlineKeyboardButton('üî∂ Heavy (3.0:1)', callback_data='enhance_heavy')],
            [InlineKeyboardButton('‚óÄÔ∏è –ù–∞–∑–∞–¥', callback_data='back_main')]
        ]
        await q.edit_message_text('–£—Ä–æ–≤–µ–Ω—å –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏:', reply_markup=InlineKeyboardMarkup(kb))
        return

    if act == 'convert_menu':
        kb = [
            [InlineKeyboardButton('üíé FLAC (–±–µ–∑ –ø–æ—Ç–µ—Ä—å)', callback_data='convert_flac')],
            [InlineKeyboardButton('üéµ MP3 320kbps', callback_data='convert_mp3')],
            [InlineKeyboardButton('üé∂ OGG Vorbis q10', callback_data='convert_ogg')],
            [InlineKeyboardButton('üìª WAV (PCM)', callback_data='convert_wav')],
            [InlineKeyboardButton('‚óÄÔ∏è –ù–∞–∑–∞–¥', callback_data='back_main')]
        ]
        await q.edit_message_text('–§–æ—Ä–º–∞—Ç:', reply_markup=InlineKeyboardMarkup(kb))
        return

    if act == 'back_main':
        kb = [
            [InlineKeyboardButton('üìä –ê–Ω–∞–ª–∏–∑', callback_data='analyze'), InlineKeyboardButton('üìà –°–ø–µ–∫—Ç—Ä', callback_data='spectrum')],
            [InlineKeyboardButton('‚ú® –£–ª—É—á—à–∏—Ç—å', callback_data='enhance_menu'), InlineKeyboardButton('üîä –ù–æ—Ä–º.', callback_data='normalize')],
            [InlineKeyboardButton('üíæ –ö–æ–Ω–≤–µ—Ä—Ç', callback_data='convert_menu'), InlineKeyboardButton('üöÄ –ü–æ–ª–Ω–∞—è', callback_data='full_process')]
        ]
        await q.edit_message_text('–í—ã–±–µ—Ä–∏—Ç–µ:', reply_markup=InlineKeyboardMarkup(kb))
        return

    if uid not in user_data: user_data[uid] = {}
    user_data[uid]['action'] = act

    names = {
        'analyze': 'üìä –ê–Ω–∞–ª–∏–∑', 'spectrum': 'üìà –°–ø–µ–∫—Ç—Ä',
        'enhance_light': '‚ú® Light (1.5:1)', 'enhance_medium': '‚ú® Medium (2.0:1)', 'enhance_heavy': '‚ú® Heavy (3.0:1)',
        'normalize': 'üîä –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è', 'mono_to_stereo': 'üéµ –°—Ç–µ—Ä–µ–æ',
        'convert_flac': 'üíæ FLAC', 'convert_mp3': 'üíæ MP3', 'convert_ogg': 'üíæ OGG', 'convert_wav': 'üíæ WAV',
        'full_process': 'üöÄ –ü–æ–ª–Ω–∞—è'
    }
    await q.edit_message_text(f'*{names.get(act, act)}*\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ', parse_mode='Markdown')

async def handle_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.message.from_user.id

    if not rate_limiter.is_allowed(uid):
        wt = int(rate_limiter.get_wait_time(uid))
        await update.message.reply_text(f'‚è±Ô∏è –ü–æ–¥–æ–∂–¥–∏—Ç–µ {wt} —Å–µ–∫')
        return

    if uid not in user_data or 'action' not in user_data[uid]:
        kb = [[InlineKeyboardButton('üìä –ê–Ω–∞–ª–∏–∑', callback_data='analyze'), InlineKeyboardButton('‚ú® –£–ª—É—á—à–∏—Ç—å', callback_data='enhance_menu')], [InlineKeyboardButton('üöÄ –ü–æ–ª–Ω–∞—è', callback_data='full_process')]]
        await update.message.reply_text('–í—ã–±–µ—Ä–∏—Ç–µ:', reply_markup=InlineKeyboardMarkup(kb))
        return

    act = user_data[uid]['action']

    if update.message.audio:
        file = await update.message.audio.get_file()
        fname = update.message.audio.file_name or 'audio.mp3'
        fsize = update.message.audio.file_size
    elif update.message.voice:
        file = await update.message.voice.get_file()
        fname = 'voice.ogg'
        fsize = update.message.voice.file_size
    elif update.message.document:
        file = await update.message.document.get_file()
        fname = update.message.document.file_name
        fsize = update.message.document.file_size
    else:
        await update.message.reply_text('‚ùå –§–æ—Ä–º–∞—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è')
        return

    fsize_mb = fsize / (1024*1024) if fsize else 0
    if fsize_mb > MAX_FILE_SIZE_MB:
        await update.message.reply_text(f'‚ùå –§–∞–π–ª {fsize_mb:.1f} –ú–ë > {MAX_FILE_SIZE_MB} –ú–ë')
        return

    await update.message.reply_text(f'‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ ({fsize_mb:.1f} –ú–ë)...')

    inp = outp = None
    try:
        inp = FileManager.get_safe_path(uid, 'in')
        await file.download_to_drive(inp)

        audio = AudioSegment.from_file(inp)
        dur = len(audio) / 1000.0

        logger.info(f'–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {fname}, {dur:.1f}—Å, {audio.frame_rate}Hz, {audio.sample_width*8}bit, {audio.channels}ch')

        update_stats(uid, act)

        if act == 'analyze':
            s = AudioProcessor.analyze_audio(audio)
            txt = f'üìä *–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑*\n\nüéµ –ö–∞–Ω–∞–ª—ã: {"–ú–æ–Ω–æ" if s["is_mono"] else "–°—Ç–µ—Ä–µ–æ"}\nüì° –ß–∞—Å—Ç–æ—Ç–∞: {s["sample_rate"]} Hz\nüéöÔ∏è –ë–∏—Ç–Ω–æ—Å—Ç—å: {s["bit_depth"]} bit\n‚è± –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {s["duration"]:.1f} —Å–µ–∫\nüì¶ –†–∞–∑–º–µ—Ä: {fsize_mb:.1f} –ú–ë\n\nüìà –ö–∞—á–µ—Å—Ç–≤–æ: {s["quality"]}%\nüìä RMS: {s["rms"]:.3f}\nüîä Peak: {s["peak"]:.3f}\nüéö –î–∏–Ω–∞–º–∏–∫–∞: {s["dynamic_range"]:.1f} dB\nüîâ –ì—Ä–æ–º–∫–æ—Å—Ç—å: {s["lufs"]} LUFS'
            await update.message.reply_text(txt, parse_mode='Markdown')

        elif act == 'spectrum':
            spec = AudioProcessor.create_spectrum_chart(audio)
            s = AudioProcessor.analyze_audio(audio)
            await update.message.reply_photo(photo=spec, caption=f'üìà *–°–ø–µ–∫—Ç—Ä*\n\n{s["sample_rate"]} Hz\n{s["dynamic_range"]:.1f} dB', parse_mode='Markdown')

        elif act == 'normalize':
            before = AudioProcessor.analyze_audio(audio)
            await update.message.reply_text('üîä –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è...')
            norm = AudioProcessor.normalize_loudness(audio, -16)
            after = AudioProcessor.analyze_audio(norm)

            outp = FileManager.get_safe_path(uid, 'out', '.flac')
            norm.export(outp, format='flac', parameters=["-compression_level", "8"])

            with open(outp, 'rb') as f:
                await update.message.reply_audio(audio=f, filename=fname.rsplit('.', 1)[0]+'_NORM.flac', caption=f'üîä *–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ*\n\nüìâ –î–æ: {before["lufs"]} LUFS\nüìà –ü–æ—Å–ª–µ: {after["lufs"]} LUFS', parse_mode='Markdown')

        elif act == 'mono_to_stereo':
            if audio.channels == 1:
                audio = AudioProcessor.mono_to_stereo(audio)
                outp = FileManager.get_safe_path(uid, 'out', '.flac')
                audio.export(outp, format='flac')
                with open(outp, 'rb') as f:
                    await update.message.reply_audio(audio=f, filename=fname.replace('.', '_STEREO.'), caption='‚úÖ –ú–æ–Ω–æ ‚Üí –°—Ç–µ—Ä–µ–æ')
            else:
                await update.message.reply_text('‚ÑπÔ∏è –£–∂–µ —Å—Ç–µ—Ä–µ–æ')

        elif act.startswith('enhance_'):
            lvl = act.split('_')[1]
            before = AudioProcessor.analyze_audio(audio)
            await update.message.reply_text(f'‚ú® –ú—è–≥–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ ({lvl})...')

            enh = AudioProcessor.enhance_audio(audio, lvl)
            after = AudioProcessor.analyze_audio(enh)

            outp = FileManager.get_safe_path(uid, 'out', '.flac')
            enh.export(outp, format='flac', parameters=["-compression_level", "8"])

            chart = AudioProcessor.create_comparison_chart(before, after)
            await update.message.reply_photo(photo=chart, caption=f'üìä –†–µ–∑—É–ª—å—Ç–∞—Ç')

            ratio_map = {'light': '1.5:1', 'medium': '2.0:1', 'heavy': '3.0:1'}

            with open(outp, 'rb') as f:
                await update.message.reply_audio(audio=f, filename=fname.rsplit('.', 1)[0]+f'_[{lvl.upper()}].flac',
                    caption=f'‚úÖ *–£–ª—É—á—à–µ–Ω–æ ({ratio_map[lvl]})*\n\nüìä –ö–∞—á–µ—Å—Ç–≤–æ: {before["quality"]}% ‚Üí {after["quality"]}%\nüéö –î–∏–Ω–∞–º–∏–∫–∞: {before["dynamic_range"]:.1f} ‚Üí {after["dynamic_range"]:.1f} dB\nüîâ LUFS: {before["lufs"]} ‚Üí {after["lufs"]}',
                    parse_mode='Markdown')

        elif act.startswith('convert_'):
            fmt = act.split('_')[1]
            await update.message.reply_text(f'üíæ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ {fmt.upper()}...')

            outp = FileManager.get_safe_path(uid, 'out', f'.{fmt}')

            if fmt == 'mp3':
                audio.export(outp, format='mp3', bitrate='320k', parameters=["-q:a", "0"])
            elif fmt == 'ogg':
                audio.export(outp, format='ogg', codec='libvorbis', parameters=["-qscale:a", "10"])
            elif fmt == 'wav':
                audio.export(outp, format='wav')
            else:
                audio.export(outp, format='flac', parameters=["-compression_level", "8"])

            with open(outp, 'rb') as f:
                await update.message.reply_audio(audio=f, filename=fname.rsplit('.', 1)[0]+f'.{fmt}', caption=f'üíæ *{fmt.upper()}*', parse_mode='Markdown')

        elif act == 'full_process':
            if dur > 300:
                await update.message.reply_text('‚ö†Ô∏è –§–∞–π–ª > 5 –º–∏–Ω\n\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏')
                if inp and os.path.exists(inp): os.remove(inp)
                return

            await update.message.reply_text(f'üöÄ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ({dur:.0f}—Å)...')
            before = AudioProcessor.analyze_audio(audio)

            if audio.channels == 1:
                audio = AudioProcessor.mono_to_stereo(audio)
                await update.message.reply_text('‚úì –°—Ç–µ—Ä–µ–æ')

            enh = AudioProcessor.enhance_audio(audio, 'medium')
            await update.message.reply_text('‚úì –ú—è–≥–∫–∞—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è (2:1)')

            after = AudioProcessor.analyze_audio(enh)

            outp = FileManager.get_safe_path(uid, 'out', '.flac')
            await update.message.reply_text('üíæ –≠–∫—Å–ø–æ—Ä—Ç FLAC...')
            enh.export(outp, format='flac', parameters=["-compression_level", "8"])

            if dur <= 120:
                try:
                    chart = AudioProcessor.create_comparison_chart(before, after)
                    await update.message.reply_photo(photo=chart, caption='üìä –î–æ/–ü–æ—Å–ª–µ')
                except: pass

                try:
                    spec = AudioProcessor.create_spectrum_chart(enh)
                    await update.message.reply_photo(photo=spec, caption='üìà –°–ø–µ–∫—Ç—Ä')
                except: pass

            await update.message.reply_text('üì§ –û—Ç–ø—Ä–∞–≤–∫–∞...')
            with open(outp, 'rb') as f:
                await update.message.reply_audio(audio=f, filename=fname.rsplit('.', 1)[0]+'_[PRO-v2.2].flac',
                    caption=f'‚úÖ *PRO v2.2!*\n\nüìä –ö–∞—á–µ—Å—Ç–≤–æ: {before["quality"]}% ‚Üí {after["quality"]}%\nüéµ {"–ú–æ–Ω–æ" if before["is_mono"] else "–°—Ç–µ—Ä–µ–æ"} ‚Üí –°—Ç–µ—Ä–µ–æ\nüéö –î–∏–Ω–∞–º–∏–∫–∞: {before["dynamic_range"]:.1f} ‚Üí {after["dynamic_range"]:.1f} dB\nüîâ LUFS: {before["lufs"]} ‚Üí {after["lufs"]}\n\n‚ú® –ú—è–≥–∫–∞—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è 2:1',
                    parse_mode='Markdown', read_timeout=180, write_timeout=180)

            await update.message.reply_text('‚úÖ –ì–æ—Ç–æ–≤–æ!')

        if inp and os.path.exists(inp): os.remove(inp)
        if outp and os.path.exists(outp): os.remove(outp)

        kb = [[InlineKeyboardButton('üìä –ê–Ω–∞–ª–∏–∑', callback_data='analyze'), InlineKeyboardButton('‚ú® –£–ª—É—á—à–∏—Ç—å', callback_data='enhance_menu')], [InlineKeyboardButton('üöÄ –ü–æ–ª–Ω–∞—è', callback_data='full_process')]]
        await update.message.reply_text('–ï—â—ë?', reply_markup=InlineKeyboardMarkup(kb))

    except Exception as e:
        logger.error(f'‚ùå {e}', exc_info=True)
        await update.message.reply_text(f'‚ùå –û—à–∏–±–∫–∞: {str(e)}')
        if inp and os.path.exists(inp):
            try: os.remove(inp)
            except: pass
        if outp and os.path.exists(outp):
            try: os.remove(outp)
            except: pass

def main():
    if not BOT_TOKEN or BOT_TOKEN == 'YOUR_BOT_TOKEN':
        logger.error('‚ùå BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!')
        return

    os.makedirs('/app/temp', exist_ok=True)
    os.makedirs('/app/logs', exist_ok=True)

    FileManager.start_cleanup_scheduler()

    app = Application.builder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler('start', start))
    app.add_handler(CallbackQueryHandler(button_callback))
    app.add_handler(MessageHandler(filters.AUDIO | filters.VOICE | filters.Document.AUDIO, handle_audio))

    logger.info('üöÄ –ë–æ—Ç PRO v2.2 –∑–∞–ø—É—â–µ–Ω! (SOFT Compression)')
    logger.info(f'‚öôÔ∏è  –ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE_MB} –ú–ë')

    app.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main()
